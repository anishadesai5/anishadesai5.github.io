---
layout: post
title: Web Scraping basics and using Beautiful Soup 
excerpt: Scraping done from three different websites
permalink: /web_scraping
publish: false
tags: [HTML, CSS, Github, Python, Scraping, Beautiful Soup, Web data]
---

<link href="https://afeld.github.io/emoji-css/emoji.css" rel="stylesheet">

Github repository <a href = "https://github.com/anishadesai5/Web-Scrapping" target="_blank">here</a>

<h2>Introduction </h2>

<p>
Web Scraping - An automatic way to retrieve unstructured or semi-structured data from a website and store them in a structured format. 
  Web Scrapers can extract all the data on particular sites or the specific data that a user wants. 
  Ideally, itâ€™s best if you specify the data you want so that the web scraper only extracts that data quickly.  </p>

<h3> 
	Challenges of web scraping </h3>

<ul>
  <li>It is more complex than other ways of getting data. APIs</li>
  <li>It may be fragile - Frequently changing web designs</li>
  <li>Ethical and legal risks</li>
  <li>Reality - Website designs are getting better. Are you a robot? </li> 
</ul>

<h3> 
	Benefits of web scraping </h3>

<ul>
  <li>Can be run iteratively over many web pages</li>
  <li>Some websites have thousand or millions of pages</li>
  <li>Can construct large, robust data sets out of otherwise messy text that would only appear in your web browser.</li>
</ul>

<h3> 
	Basics of Web Scraping </h3>

<ul>
  <li>1. Finding the address - URL or URLs</li>
  <li>2. Sending HTTP requests to the server</li>
  <li>3. Parse the return</li>
  <li>4. Store the results</li>
</ul>


<h3> 
	Important Steps to follow </h3>

<ul>
  <li>1. Indentify the url patterns</li>
  <li>2. Inspect the source code and locate data elements</li>
  <li>3. Think about the logical flow of your crawler</li>
  <li>4. Persistence and creativity is often required to collect valuable data</li>
</ul>

<h3> 
	Techniques covered in the 3 parts of web scraping </h3>

<ul>
  <li>Techniques for identifing url patterns</li>
  <li>How to inspect html in a browser</li>
  <li>How to request html with Python</li>
  <li>Techniques for finding the data</li>
  <li>Techniques for parsing html</li>
  <li>BeautifulSoup</li>
</ul>

<h3> 
	The website URLS from where we will be scraping the data </h3>

<ul>
  <li>https://www.indiana-demographics.com/cities_by_population</li>
  <li>https://www.getcompanyinfo.com/industry/information-technology-services/</li>
  <li>https://quotes.toscrape.com/</li>
</ul>
	
